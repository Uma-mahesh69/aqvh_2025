{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Fraud Detection - Quick Start Notebook\n",
    "\n",
    "This notebook demonstrates how to run the quantum fraud detection pipeline interactively.\n",
    "\n",
    "## Overview\n",
    "- **Classical Models**: Logistic Regression, Isolation Forest, XGBoost\n",
    "- **Quantum Models**: VQC, Quantum Kernel\n",
    "- **Backends**: Simulator, Aer, IBM Quantum Hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_loader import load_csvs, merge_on_transaction_id\n",
    "from src.preprocessing import PreprocessConfig, preprocess_pipeline, split_data\n",
    "from src.model_classical import (\n",
    "    ClassicalConfig, train_logreg,\n",
    "    IsolationForestConfig, train_isolation_forest,\n",
    "    XGBoostConfig, train_xgboost\n",
    ")\n",
    "from src.model_quantum import (\n",
    "    QuantumConfig, train_vqc,\n",
    "    QuantumKernelConfig, train_quantum_kernel\n",
    ")\n",
    "from src.quantum_backend import BackendConfig\n",
    "from src import evaluation as eval_mod\n",
    "from src.results_comparison import save_all_results\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Dataset: {config['data']['transaction_csv']}\")\n",
    "print(f\"- Features to select: {config['preprocessing']['top_k_corr_features']}\")\n",
    "print(f\"- Backend: {config['quantum_backend']['backend_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "df_txn, df_id = load_csvs(\n",
    "    config['data']['transaction_csv'],\n",
    "    config['data']['identity_csv']\n",
    ")\n",
    "df = merge_on_transaction_id(df_txn, df_id)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Fraud rate: {df['isFraud'].mean():.2%}\")\n",
    "\n",
    "# Display sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "print(\"Preprocessing data...\")\n",
    "pp_cfg = PreprocessConfig(\n",
    "    missing_threshold=config['preprocessing']['missing_threshold'],\n",
    "    target_col=config['preprocessing']['target_col'],\n",
    "    id_cols=config['preprocessing']['id_cols'],\n",
    "    top_k_corr_features=config['preprocessing']['top_k_corr_features'],\n",
    ")\n",
    "\n",
    "df_processed, selected_features = preprocess_pipeline(df, pp_cfg)\n",
    "\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(f\"Processed shape: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    df_processed,\n",
    "    target=pp_cfg.target_col,\n",
    "    test_size=config['preprocessing']['test_size'],\n",
    "    random_state=config['preprocessing']['random_state'],\n",
    "    stratify=config['preprocessing']['stratify'],\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Train fraud rate: {y_train.mean():.2%}\")\n",
    "print(f\"Test fraud rate: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Classical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Logistic Regression...\")\n",
    "lr_cfg = ClassicalConfig(\n",
    "    penalty=config['logistic_regression']['penalty'],\n",
    "    C=config['logistic_regression']['C'],\n",
    "    max_iter=config['logistic_regression']['max_iter'],\n",
    "    use_random_oversampler=config['logistic_regression']['use_random_oversampler'],\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "lr_model = train_logreg(X_train.values, y_train.values, lr_cfg)\n",
    "lr_time = time.time() - start\n",
    "\n",
    "# Evaluate\n",
    "y_pred_lr = lr_model.predict(X_test.values)\n",
    "y_proba_lr = lr_model.predict_proba(X_test.values)[:, 1]\n",
    "lr_metrics = eval_mod.compute_metrics(y_test.values, y_pred_lr, y_proba_lr)\n",
    "\n",
    "print(f\"Training time: {lr_time:.2f}s\")\n",
    "print(f\"Metrics: {lr_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Isolation Forest...\")\n",
    "if_cfg = IsolationForestConfig(\n",
    "    n_estimators=config['isolation_forest']['n_estimators'],\n",
    "    contamination=config['isolation_forest']['contamination'],\n",
    "    random_state=config['isolation_forest']['random_state'],\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "if_model = train_isolation_forest(X_train.values, y_train.values, if_cfg)\n",
    "if_time = time.time() - start\n",
    "\n",
    "# Evaluate (convert -1/1 to 0/1)\n",
    "y_pred_if = if_model.predict(X_test.values)\n",
    "y_pred_if = np.where(y_pred_if == -1, 1, 0)\n",
    "y_score_if = if_model.decision_function(X_test.values)\n",
    "if_metrics = eval_mod.compute_metrics(y_test.values, y_pred_if, y_score_if)\n",
    "\n",
    "print(f\"Training time: {if_time:.2f}s\")\n",
    "print(f\"Metrics: {if_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training XGBoost...\")\n",
    "xgb_cfg = XGBoostConfig(\n",
    "    n_estimators=config['xgboost']['n_estimators'],\n",
    "    max_depth=config['xgboost']['max_depth'],\n",
    "    learning_rate=config['xgboost']['learning_rate'],\n",
    "    random_state=config['xgboost']['random_state'],\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "xgb_model = train_xgboost(X_train.values, y_train.values, xgb_cfg)\n",
    "xgb_time = time.time() - start\n",
    "\n",
    "# Evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test.values)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test.values)[:, 1]\n",
    "xgb_metrics = eval_mod.compute_metrics(y_test.values, y_pred_xgb, y_proba_xgb)\n",
    "\n",
    "print(f\"Training time: {xgb_time:.2f}s\")\n",
    "print(f\"Metrics: {xgb_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Quantum Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Variational Quantum Classifier (VQC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Quantum VQC...\")\n",
    "print(\"⚠️ This may take several minutes...\")\n",
    "\n",
    "# Setup backend\n",
    "backend_cfg = BackendConfig(\n",
    "    backend_type=config['quantum_backend']['backend_type'],\n",
    "    shots=config['quantum_backend']['shots'],\n",
    ")\n",
    "\n",
    "vqc_cfg = QuantumConfig(\n",
    "    num_features=X_train.shape[1],\n",
    "    reps_feature_map=config['quantum_vqc']['reps_feature_map'],\n",
    "    reps_ansatz=config['quantum_vqc']['reps_ansatz'],\n",
    "    optimizer_maxiter=config['quantum_vqc']['optimizer_maxiter'],\n",
    "    backend_config=backend_cfg,\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "vqc_model = train_vqc(X_train.values, y_train.values, vqc_cfg)\n",
    "vqc_time = time.time() - start\n",
    "\n",
    "# Evaluate\n",
    "y_pred_vqc = vqc_model.predict(X_test.values)\n",
    "try:\n",
    "    y_proba_vqc = vqc_model.predict_proba(X_test.values)[:, 1]\n",
    "except:\n",
    "    y_proba_vqc = None\n",
    "vqc_metrics = eval_mod.compute_metrics(y_test.values, y_pred_vqc, y_proba_vqc)\n",
    "\n",
    "print(f\"✓ Training complete!\")\n",
    "print(f\"Training time: {vqc_time:.2f}s\")\n",
    "print(f\"Metrics: {vqc_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Quantum Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Quantum Kernel...\")\n",
    "print(\"⚠️ This may take several minutes...\")\n",
    "\n",
    "qk_cfg = QuantumKernelConfig(\n",
    "    num_features=X_train.shape[1],\n",
    "    reps_feature_map=config['quantum_kernel']['reps_feature_map'],\n",
    "    C=config['quantum_kernel']['C'],\n",
    "    backend_config=backend_cfg,\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "qk_model = train_quantum_kernel(X_train.values, y_train.values, qk_cfg)\n",
    "qk_time = time.time() - start\n",
    "\n",
    "# Evaluate\n",
    "y_pred_qk = qk_model.predict(X_test.values)\n",
    "y_proba_qk = qk_model.predict_proba(X_test.values)[:, 1]\n",
    "qk_metrics = eval_mod.compute_metrics(y_test.values, y_pred_qk, y_proba_qk)\n",
    "\n",
    "print(f\"✓ Training complete!\")\n",
    "print(f\"Training time: {qk_time:.2f}s\")\n",
    "print(f\"Metrics: {qk_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "all_metrics = {\n",
    "    'Logistic Regression': lr_metrics,\n",
    "    'Isolation Forest': if_metrics,\n",
    "    'XGBoost': xgb_metrics,\n",
    "    'Quantum VQC': vqc_metrics,\n",
    "    'Quantum Kernel': qk_metrics,\n",
    "}\n",
    "\n",
    "all_times = {\n",
    "    'Logistic Regression': lr_time,\n",
    "    'Isolation Forest': if_time,\n",
    "    'XGBoost': xgb_time,\n",
    "    'Quantum VQC': vqc_time,\n",
    "    'Quantum Kernel': qk_time,\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame(all_metrics).T\n",
    "results_df['training_time'] = pd.Series(all_times)\n",
    "results_df = results_df.sort_values('f1', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# F1 Score comparison\n",
    "ax1 = axes[0]\n",
    "colors = ['#4ECDC4' if 'Quantum' not in name else '#FF6B6B' for name in results_df.index]\n",
    "results_df['f1'].plot(kind='barh', ax=ax1, color=colors)\n",
    "ax1.set_xlabel('F1 Score')\n",
    "ax1.set_title('Model Performance Comparison')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Training time comparison\n",
    "ax2 = axes[1]\n",
    "results_df['training_time'].plot(kind='barh', ax=ax2, color=colors)\n",
    "ax2.set_xlabel('Training Time (seconds)')\n",
    "ax2.set_title('Training Time Comparison')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quantum Advantage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate classical and quantum results\n",
    "classical_models = ['Logistic Regression', 'Isolation Forest', 'XGBoost']\n",
    "quantum_models = ['Quantum VQC', 'Quantum Kernel']\n",
    "\n",
    "classical_f1 = results_df.loc[classical_models, 'f1'].max()\n",
    "quantum_f1 = results_df.loc[quantum_models, 'f1'].max()\n",
    "\n",
    "improvement = ((quantum_f1 - classical_f1) / classical_f1) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUANTUM ADVANTAGE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best Classical F1: {classical_f1:.4f}\")\n",
    "print(f\"Best Quantum F1: {quantum_f1:.4f}\")\n",
    "print(f\"Improvement: {improvement:+.2f}%\")\n",
    "print()\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"✅ Quantum models show advantage over classical models!\")\n",
    "elif improvement > -5:\n",
    "    print(\"⚖️ Quantum and classical models show comparable performance.\")\n",
    "else:\n",
    "    print(\"❌ Classical models currently outperform quantum models.\")\n",
    "    print(\"   Consider: more training data, hyperparameter tuning, or different feature selection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive results\n",
    "output_dir = '../results'\n",
    "save_all_results(all_metrics, all_times, output_dir)\n",
    "\n",
    "print(f\"\\n✓ All results saved to: {output_dir}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"- metrics_comparison.png\")\n",
    "print(\"- metrics_table.csv\")\n",
    "print(\"- training_time_comparison.png\")\n",
    "print(\"- quantum_advantage_report.txt\")\n",
    "print(\"- results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "### Experiment Ideas:\n",
    "\n",
    "1. **Try different feature counts:**\n",
    "   ```python\n",
    "   # Modify preprocessing config\n",
    "   pp_cfg.top_k_corr_features = 6  # Try 4, 6, 8, 10\n",
    "   ```\n",
    "\n",
    "2. **Test on IBM Quantum Hardware:**\n",
    "   ```python\n",
    "   backend_cfg = BackendConfig(\n",
    "       backend_type=\"ibm_quantum\",\n",
    "       ibm_token=\"YOUR_TOKEN\",\n",
    "       ibm_backend_name=\"ibm_brisbane\",\n",
    "       shots=1024\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. **Tune quantum circuit depth:**\n",
    "   ```python\n",
    "   vqc_cfg.reps_feature_map = 3\n",
    "   vqc_cfg.reps_ansatz = 3\n",
    "   ```\n",
    "\n",
    "4. **Optimize classical models:**\n",
    "   ```python\n",
    "   xgb_cfg.n_estimators = 200\n",
    "   xgb_cfg.max_depth = 8\n",
    "   ```\n",
    "\n",
    "### Analysis:\n",
    "- Compare confusion matrices\n",
    "- Analyze feature importance\n",
    "- Study quantum circuit properties\n",
    "- Investigate failure cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
